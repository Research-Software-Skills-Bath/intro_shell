{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compute Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview:\n",
    "- **Teaching:** 10 min\n",
    "- **Exercises:** 0 min\n",
    "\n",
    "**Questions**\n",
    "- What compute instances are available?\n",
    "- How do I choose the right instance?\n",
    "- What do these cost?\n",
    "- How do I see the partitions?\n",
    "- What is spot and Pay as you Go?\n",
    "\n",
    "**Objectives**\n",
    "- Understand what compute instances are currently available\n",
    "- Know where to get information on the compute instances, including costs\n",
    "- Understand the difference between spot and pay-as-you-go\n",
    "- Know which instance to use for your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Slurm partitions\n",
    "\n",
    "The new hpc service Janus provides user access to an array of different compute instances. These instances are accessed through different slurm partitions.\n",
    "\n",
    "In order to list the partitions issue the following command:\n",
    "\n",
    "`sinfo`\n",
    "\n",
    "which will list the partitions, the nodes in the partitions, availability and the current state:\n",
    "\n",
    "![linux-login](../images/janus-partitions.png)\n",
    "\n",
    "The partitions follow a naming converntion:\n",
    "\n",
    "`[pricing tier]-[instance type]-[no of cpus-per-node]`\n",
    "\n",
    "So, for example the partition `spot-hbv3-120` is for spot priced hbv3 instances with 120 CPUs per node, while `paygo-hbv3-32` is for pay-as-you-go priced instances with 32 CPUs per node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Instances \n",
    "\n",
    "The instance types currently available are listed below:\n",
    "    \n",
    "| Instance type | CPU model | vCPUS | GPU model |vGPUS|\n",
    "|---|---|---|---|---|\n",
    "| fsv2  | Intel Skylake | 2,4,8,16,32,48,64,72 | - | -|\n",
    "| hb    | AMD Epyc Naples | 60 | - | - |\n",
    "| hbv2  | AMD Epyc Rome | 120 | - | - |\n",
    "| hbv3  | AMD Epyc Milan | 120 | - | - |\n",
    "| hc    | Intel Skylake | 44 | - | - |\n",
    "| ncv3  | Intel Broadwell | 6 | Tesla V100 | 1 |\n",
    "| ncv3  | Intel Broadwell | 12 | Tesla V100 | 2 |\n",
    "| ncv3  | Intel Broadwell | 24 | Tesla V100 | 4 |\n",
    "| ncv3r | Intel Broadwell | 24 | Tesla V100 | 4 |\n",
    "| ndv2  | Intel Skylake   | 40 | Tesla V100 | 8 |\n",
    "\n",
    "\n",
    "As mentioned above these instances are referenced in the slurm partition, along with the number of CPUs and the pricing tier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information: Instance types\n",
    "\n",
    "You can read more about the instance types here: https://docs.microsoft.com/en-us/azure/virtual-machines/sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the right instance\n",
    "\n",
    "Choosing the correct compute instance and partition will depend primarily on the code/caculation you are running, but it also will depend on cost, runtime and whether an interruption is acceptable (more on that in spot vs pay-as-you-go).\n",
    "\n",
    "The compute instances listed above can be seperated into different types as described by azure:\n",
    "\n",
    "- **High performance compute**: hb, hbv2, hbv3 & hc series\n",
    "- **GPU enabled**: ncv3, ncv3r, & ndv2\n",
    "- **Compute Optimised**: fsv2\n",
    "\n",
    "The descriptions of the instances provided by Azure are as follows:\n",
    "\n",
    "- **High Performance Compute**: `Our fastest and most powerful CPU virtual machines with optional high-throughput network interfaces (RDMA).`\n",
    "- **GPU enabled**: `Specialized virtual machines targeted for heavy graphic rendering and video editing, as well as model training and inferencing (ND) with deep learning. Available with single or multiple GPUs.`\n",
    "- **Compute Optimised**: `High CPU-to-memory ratio. Good for medium traffic web servers, network appliances, batch processes, and application servers.`\n",
    "\n",
    "Briefly:\n",
    "- The `hb*` instances are suggested for applications driven by memory bandwidth such as OpenFOAM and ANSYS.\n",
    "- The `hc*` & `f*` instances are suggested for applications driven by compute such as HPL and ORCA.\n",
    "- The `n*` partitions are suggested for GPU accelerated applications, like NAMD.\n",
    "\n",
    "If in doubt - ask or test!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spot vs Pay-As-You-Go\n",
    "\n",
    "We have mentioned the `pricing tier` above, which is referenced in the slurm partition names. This pricing tier refers to the two different tiers:\n",
    "- Spot\n",
    "- Pay-As-You-go\n",
    "\n",
    "Spot pricing allows access to unused Azure compute capacity at large discounts, up to 90%, compared to Pay-As-You-Go prices. The drawback is that the job can be interrupted at any time and be evicted, depending on the available Azure capacity.\n",
    "\n",
    "Deciding whether to use the Spot or Pay-As-You-Go tiers will depend on how easy it is to pick up your calculation should it be evicted, the time scales for you calculation and your available budget.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrictions on Instances\n",
    "\n",
    "Some restrictions are in place on the resources available. At present in the phase 1 system, while the accounting back-end is not yet implemented, users do not have access to the pay-as-you-go instances, only spot. \n",
    "\n",
    "Other restrictions on the slurm resources are in place on the spot instances:\n",
    "\n",
    "| Limit | Partitions |\n",
    "|---|---|\n",
    "|  Maximum and minimum nodes per job equal to 1 | all \\*-fsv2-\\*  |\n",
    "|  Maximum number of nodes per job equal to 4   | all \\*-hb\\*-\\*  |\n",
    "| Maximum number of nodes per job equal to 8 | all \\*-hc-\\* |\n",
    "| Maximum number of Trackable RESources (TRES) per job across all spot GPU partitions equal to 3  | \\*-ncv3\\*-\\* & \\*-ndv2\\*|\n",
    "| Maximum time per job of 36 hours  | All |\n",
    "| Minimum number of nodes per job equal to 2 on all RDMA connected nodes except GPU ones    | \\*-hb\\*-\\* & \\*-hc44-\\* |\n",
    "|Only whole nodes can be allocated to jobs|All|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicative Cost of Instances\n",
    "\n",
    "Full accounting, including transferral of premium budgets and full costings for the compute instances and storage will be brought in during phase 2 of the cloud HPC system. \n",
    "\n",
    "However it is important to emphasise that **different compute instances will incur different costs**.\n",
    "\n",
    "In order to highlight this point we can examine the current **spot** costs for the instances available as listed by Azure:\n",
    "\n",
    "| Instance type | Â£/CPUh |\n",
    "|---|---|\n",
    "| fsv2  | 0.0106 |\n",
    "| hb    | 0.0077 |\n",
    "| hbv2  | 0.0077 |\n",
    "| hbv3_120  | 0.0116 |\n",
    "| hc    | 0.0147 |\n",
    "| ncv3  | 0.0835 |\n",
    "| ncv3r | 0.0918 |\n",
    "| ndv2  | 0.0564 |\n",
    "\n",
    "While it is important to remember that these costs will be different than the final costs, these give a rough indication of the relative costings associated with a CPUh on each instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information: Pricing\n",
    "You can read more about the cost of compute instances here:https://azure.microsoft.com/en-gb/pricing/details/virtual-machines/linux/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key Points:\n",
    "- Different compute instances are accessed through different slurm partitions\n",
    "- The Slurm partitions follow the naming convention: `[pricing tier]-[instance type]-[no of cpus-per-node]`\n",
    "- There are two pricing tiers: Spot and Pay-As-You-Go. Spot benefits from significant discounts (up to 90%), but may be evicted\n",
    "- Different instances are suitable for different calculation types and will cost different amounts "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
